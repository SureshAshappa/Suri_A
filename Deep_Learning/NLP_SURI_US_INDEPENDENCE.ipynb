{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae5fea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "394cd30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\SURESH\n",
      "[nltk_data]     A\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8775f358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to C:\\Users\\SURESH\n",
      "[nltk_data]     A\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0647ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a placeholder for model\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd682cc",
   "metadata": {},
   "source": [
    "\n",
    "#About Reuters corpus\n",
    "'''The Reuters Corpus contains 10,788 news documents totaling 1.3 million \n",
    "words. The documents have been classified into 90 topics, and grouped into two \n",
    "sets, called \"training\" and \"test\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd7a3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1720901"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reuters.categories())\n",
    "len(reuters.fileids()) \n",
    "len(reuters.sents()) \n",
    "len(reuters.words()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ca49b",
   "metadata": {},
   "source": [
    "\n",
    "# Count frequency of co-occurance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f310877",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in reuters.sents(): #reading the sentence\n",
    "    for w1, w2, w3 in trigrams(sentence, pad_right=True,pad_left=True):\n",
    "        model[(w1,w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2003c84e",
   "metadata": {},
   "source": [
    "\n",
    "** w1,w2, w3 are the trigram words **\n",
    "** gving the words input in the model as 2 words as one dictionary and third **\n",
    "** wrd as another dictionary **\n",
    "** undersore can also be used as a visual separator **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b0a673b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'public': 1,\n",
       " 'European': 1,\n",
       " 'Bank': 1,\n",
       " 'price': 2,\n",
       " 'emirate': 1,\n",
       " 'overseas': 1,\n",
       " 'newspaper': 1,\n",
       " 'company': 3,\n",
       " 'Turkish': 1,\n",
       " 'increase': 1,\n",
       " 'options': 1,\n",
       " 'Higher': 1,\n",
       " 'pound': 1,\n",
       " 'Italian': 1,\n",
       " 'time': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explanation of outcome of w1,w2 & calculation of probabilities\n",
    "dict(model[\"today\", \"the\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c94c82",
   "metadata": {},
   "source": [
    "# Total = 18 ie total_count = float(sum(model[w1_w2].values())) \n",
    "# for model[w1_w2][w3] /= total_count\n",
    "# model[\"today\", \"the\"]['public'] /= total_count \n",
    "# 1/18 = 0.05555555555555555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16bf34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's transform the counts to probabilities\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b239092c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'public': 0.05555555555555555,\n",
       " 'European': 0.05555555555555555,\n",
       " 'Bank': 0.05555555555555555,\n",
       " 'price': 0.1111111111111111,\n",
       " 'emirate': 0.05555555555555555,\n",
       " 'overseas': 0.05555555555555555,\n",
       " 'newspaper': 0.05555555555555555,\n",
       " 'company': 0.16666666666666666,\n",
       " 'Turkish': 0.05555555555555555,\n",
       " 'increase': 0.05555555555555555,\n",
       " 'options': 0.05555555555555555,\n",
       " 'Higher': 0.05555555555555555,\n",
       " 'pound': 0.05555555555555555,\n",
       " 'Italian': 0.05555555555555555,\n",
       " 'time': 0.05555555555555555}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the next word\n",
    "dict(model[\"today\", \"the\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "243b4725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yesterday': 0.004651162790697674,\n",
       " 'of': 0.3209302325581395,\n",
       " 'it': 0.05581395348837209,\n",
       " 'effect': 0.004651162790697674,\n",
       " 'cut': 0.009302325581395349,\n",
       " 'for': 0.05116279069767442,\n",
       " 'paid': 0.013953488372093023,\n",
       " 'to': 0.05581395348837209,\n",
       " 'increases': 0.013953488372093023,\n",
       " 'used': 0.004651162790697674,\n",
       " 'climate': 0.004651162790697674,\n",
       " '.': 0.023255813953488372,\n",
       " 'cuts': 0.009302325581395349,\n",
       " 'reductions': 0.004651162790697674,\n",
       " 'limit': 0.004651162790697674,\n",
       " 'now': 0.004651162790697674,\n",
       " 'moved': 0.004651162790697674,\n",
       " 'per': 0.013953488372093023,\n",
       " 'adjustments': 0.004651162790697674,\n",
       " '(': 0.009302325581395349,\n",
       " 'slumped': 0.004651162790697674,\n",
       " 'is': 0.018604651162790697,\n",
       " 'move': 0.004651162790697674,\n",
       " 'evolution': 0.004651162790697674,\n",
       " 'differentials': 0.009302325581395349,\n",
       " 'went': 0.004651162790697674,\n",
       " 'the': 0.013953488372093023,\n",
       " 'factor': 0.004651162790697674,\n",
       " 'Royal': 0.004651162790697674,\n",
       " ',': 0.018604651162790697,\n",
       " 'again': 0.004651162790697674,\n",
       " 'changes': 0.004651162790697674,\n",
       " 'holds': 0.004651162790697674,\n",
       " 'has': 0.009302325581395349,\n",
       " 'fall': 0.004651162790697674,\n",
       " '-': 0.004651162790697674,\n",
       " 'from': 0.004651162790697674,\n",
       " 'base': 0.004651162790697674,\n",
       " 'on': 0.004651162790697674,\n",
       " 'review': 0.004651162790697674,\n",
       " 'while': 0.004651162790697674,\n",
       " 'collapse': 0.004651162790697674,\n",
       " 'being': 0.004651162790697674,\n",
       " 'at': 0.023255813953488372,\n",
       " 'outlook': 0.004651162790697674,\n",
       " 'rises': 0.004651162790697674,\n",
       " 'drop': 0.004651162790697674,\n",
       " 'guaranteed': 0.004651162790697674,\n",
       " ',\"': 0.004651162790697674,\n",
       " 'stayed': 0.009302325581395349,\n",
       " 'structure': 0.004651162790697674,\n",
       " 'and': 0.004651162790697674,\n",
       " 'could': 0.004651162790697674,\n",
       " 'related': 0.004651162790697674,\n",
       " 'hike': 0.004651162790697674,\n",
       " 'we': 0.004651162790697674,\n",
       " 'adjustment': 0.023255813953488372,\n",
       " 'policy': 0.004651162790697674,\n",
       " 'was': 0.009302325581395349,\n",
       " 'revision': 0.004651162790697674,\n",
       " 'freeze': 0.009302325581395349,\n",
       " 'led': 0.004651162790697674,\n",
       " 'action': 0.004651162790697674,\n",
       " 'zone': 0.004651162790697674,\n",
       " 'slump': 0.004651162790697674,\n",
       " 'had': 0.004651162790697674,\n",
       " 'difference': 0.004651162790697674,\n",
       " 'in': 0.004651162790697674,\n",
       " 'raise': 0.004651162790697674,\n",
       " 'increase': 0.009302325581395349,\n",
       " 'will': 0.013953488372093023,\n",
       " 'support': 0.004651162790697674,\n",
       " 'gap': 0.004651162790697674,\n",
       " 'would': 0.009302325581395349,\n",
       " 'projected': 0.004651162790697674,\n",
       " 'approached': 0.004651162790697674,\n",
       " 'instability': 0.004651162790697674}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model[\"the\", \"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ba22f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c60986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting words\n",
    "text = [\"today\", \"the\"]\n",
    "sentence_finished = False #Boolean value\n",
    "while not sentence_finished:\n",
    "  # select a random probability threshold  \n",
    "  r = random.random() #Generates a random number\n",
    "  accumulator = .0 # say 0.45 \n",
    "  for word in model[tuple(text[-2:])].keys(): #line 139 for exp\n",
    "      accumulator += model[tuple(text[-2:])][word] #line 148 to 150 for exp\n",
    "      # select words that are above the probability threshold\n",
    "      if accumulator >= r:\n",
    "          text.append(word)\n",
    "          break\n",
    "  if text[-2:] == [None, None]: #This happens when sentence ends\n",
    "      sentence_finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "406b0219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today the time its offer to acquire all of the financing required to approve the merger .\n"
     ]
    }
   ],
   "source": [
    "print (' '.join([t for t in text if t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a3f8e5",
   "metadata": {},
   "source": [
    "\n",
    "'''today the public is at constant risk to contaminated and adulterated meat ,\n",
    "\" Kenneth Blaylock , president and chief executive .'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5226de6d",
   "metadata": {},
   "source": [
    "# Our Own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d73f3df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\SURESH' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "pip install — ignore-installed — upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55576fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\SURESH' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "300debea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from jupyter) (5.0.3)\n",
      "Requirement already satisfied: notebook in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from jupyter) (6.3.0)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from jupyter) (5.3.4)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from jupyter) (7.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from jupyter) (6.0.7)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from jupyter) (6.4.0)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipykernel->jupyter) (7.22.0)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipykernel->jupyter) (6.1.12)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipykernel->jupyter) (5.0.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter) (5.0.6)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.17.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.7.5)\n",
      "Requirement already satisfied: pygments in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter) (2.8.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter) (3.0.17)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from traitlets>=4.1.0->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipywidgets->jupyter) (1.0.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipywidgets->jupyter) (5.1.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from ipywidgets->jupyter) (3.5.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->jupyter) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->jupyter) (4.7.1)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter) (1.15.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter) (20.3.0)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from notebook->jupyter) (20.0.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from notebook->jupyter) (20.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from notebook->jupyter) (0.9.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from notebook->jupyter) (2.11.3)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from notebook->jupyter) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from notebook->jupyter) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from jupyter-client->ipykernel->jupyter) (2.8.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets->jupyter) (227)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from terminado>=0.8.3->notebook->jupyter) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from argon2-cffi->notebook->jupyter) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from jinja2->notebook->jupyter) (1.1.1)\n",
      "Requirement already satisfied: testpath in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from nbconvert->jupyter) (0.4.4)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from nbconvert->jupyter) (0.3)\n",
      "Requirement already satisfied: bleach in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from nbconvert->jupyter) (3.3.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from nbconvert->jupyter) (0.5.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from nbconvert->jupyter) (1.4.3)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: async-generator in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter) (1.10)\n",
      "Requirement already satisfied: webencodings in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from bleach->nbconvert->jupyter) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from packaging->bleach->nbconvert->jupyter) (2.4.7)\n",
      "Requirement already satisfied: qtpy in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from qtconsole->jupyter) (1.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee72ff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (1.41.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (0.14.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (3.18.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\suresh a\\pythonjsk\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "319b1ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10689d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==1.2.0 --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78ff4c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9c4fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54547f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, GRU, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f813c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/SURESH A/Downloads/decl_independance.txt', 'r') as f:text1 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "279a08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "textlist = [line.strip() for line in text1]  # its a list 63 count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03805a51",
   "metadata": {},
   "source": [
    "'''strip:   It removes the white spaces from both ends.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05d8d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def text_cleaner(text):\n",
    "    # lower case text\n",
    "    newString = text.lower()\n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString) # to remove 's\n",
    "    # remove punctuations\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    long_words=[] \n",
    "    # remove short word\n",
    "    for i in newString.split(): #Split sentences into words\n",
    "        if len(i)>=3:           #Selecting words with length 3 or higher  \n",
    "            long_words.append(i)\n",
    "    return (\" \".join(long_words)).strip() #Joining the words into sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24efa8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the fear's of the lord is the begining of the wisdom -1\n"
     ]
    }
   ],
   "source": [
    "text = \"The fear's of the Lord is the begining of the wisdom -1\"\n",
    "newString = text.lower()\n",
    "print(newString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e94f601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the fear's of the lord is the begining of the wisdom -1\n"
     ]
    }
   ],
   "source": [
    "newString1 = re.sub(\"'s\\b\",\"\",newString) \n",
    "print(newString1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efae761d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the fear of the lord is the begining of the wisdom -1\n"
     ]
    }
   ],
   "source": [
    "newString3 = re.sub(r\"'s\\b\",\"\",newString) \n",
    "print(newString3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d9b3759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the fear s of the lord is the begining of the wisdom   \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#replaces anything other than alphabet with space\n",
    "newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "print(newString) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4855fbc",
   "metadata": {},
   "source": [
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9543bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to string using list comprehension\n",
    "\n",
    "s = ['I', 'want',4,'apples','and',18,'bananas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3589a5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want 4 apples and 18 bananas\n"
     ]
    }
   ],
   "source": [
    "#using list comprehension\n",
    "listToStr = ' '.join(map(str, s))\n",
    "print(listToStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b59f6b",
   "metadata": {},
   "source": [
    "# Length of Chatacters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8e7fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list to string\n",
    "teststring = ''.join(map(str,textlist))# as a chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec80c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply our user defined function for cleaning\n",
    "data_new = text_cleaner(teststring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f0d34bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7081"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac3443",
   "metadata": {},
   "source": [
    "# User def function for creating sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "178ccf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq(text):\n",
    "    length = 30\n",
    "    sequences = list()\n",
    "    for i in range(length, len(text)):\n",
    "        #select sequence of tokens\n",
    "        seq = text[i-length:i+1] # i starts with 30\n",
    "        #store \n",
    "        sequences.append(seq)\n",
    "    print('Total Sequences: %d' % len(sequences))\n",
    "    #gives the number of sequences ie the number of lines in the output\n",
    "    return sequences\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bcb26c",
   "metadata": {},
   "source": [
    "# creating Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "465433dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The fear of the lord is the begining of the wisdom\"\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c7d9e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "for i in range(30,50):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41510956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The fear of the lord is the beg',\n",
       " 'he fear of the lord is the begi',\n",
       " 'e fear of the lord is the begin',\n",
       " ' fear of the lord is the begini',\n",
       " 'fear of the lord is the beginin',\n",
       " 'ear of the lord is the begining',\n",
       " 'ar of the lord is the begining ',\n",
       " 'r of the lord is the begining o',\n",
       " ' of the lord is the begining of',\n",
       " 'of the lord is the begining of ',\n",
       " 'f the lord is the begining of t',\n",
       " ' the lord is the begining of th',\n",
       " 'the lord is the begining of the',\n",
       " 'he lord is the begining of the ',\n",
       " 'e lord is the begining of the w',\n",
       " ' lord is the begining of the wi',\n",
       " 'lord is the begining of the wis',\n",
       " 'ord is the begining of the wisd',\n",
       " 'rd is the begining of the wisdo',\n",
       " 'd is the begining of the wisdom']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_seq(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f67d2",
   "metadata": {},
   "source": [
    "# Apply function to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8eddb844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 7051\n"
     ]
    }
   ],
   "source": [
    "#create sequences\n",
    "sequences = create_seq(data_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65309a5",
   "metadata": {},
   "source": [
    "# Character Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82eeb274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "char = sorted(list(set(data_new)))\n",
    "print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6e0c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict((c, i) for i,c in enumerate(char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08e8642b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "print(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1adfe13",
   "metadata": {},
   "source": [
    "# User def function for encoding characters inside the sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b188c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode_deq converts the text into numbers as per mapping index\n",
    "\n",
    "def encode_seq(seq):\n",
    "    sequences = list()\n",
    "    for line in seq:\n",
    "        # integer encode line\n",
    "        encoded_seq = [mapping[char] for char in line]\n",
    "        # store\n",
    "        sequences.append(encoded_seq)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff92093",
   "metadata": {},
   "source": [
    "# Example of encoding characters as per our mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5403d256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping['t']\n",
    "mapping['h']\n",
    "mapping['e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79c1f977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20], [8], [5], [0], [6], [5], [1], [18], [0], [15], [6], [0], [20], [8], [5], [0], [12], [15], [18], [4], [0], [9], [19], [0], [20], [8], [5], [0], [7], [5], [7], [9], [14], [9], [14], [7], [0], [15], [6], [0], [20], [8], [5], [0], [23], [9], [19], [4], [15], [13]]\n"
     ]
    }
   ],
   "source": [
    "text = \"The fear of the lord is the gegining of the wisdom\"\n",
    "text = text.lower()\n",
    "print(encode_seq(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6168c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the sequences\n",
    "sequences1 = encode_seq(sequences)# convertion all the text to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "812d7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0be646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vacabulary size\n",
    "vocab = len(mapping)\n",
    "sequences2 = np.array(sequences1)# converted list to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d771922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X and Y\n",
    "X, y = sequences2[:,:-1], sequences2[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b68734eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode y\n",
    "y = to_categorical(y, num_classes=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c351a024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (6345, 30) Val shape: (706, 30)\n"
     ]
    }
   ],
   "source": [
    "X_tr,X_val,y_tr,y_val = train_test_split(X,y,test_size=0.1,random_state=42)\n",
    "print('train shape:',X_tr.shape,'Val shape:',X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24d0f5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_tr shape: (6345, 27) y_val shape: (706, 27)\n"
     ]
    }
   ],
   "source": [
    "print('y_tr shape:',y_tr.shape, 'y_val shape:',y_val.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c043d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2526f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(vocab, 50, input_length=30, trainable=True)) #Vocab size = vocab,  output dim = 50\n",
    "model1.add(GRU(150, recurrent_dropout=0.1, dropout=0.1)) #Gated Recurrent Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f5e93e",
   "metadata": {},
   "source": [
    "units: Positive integer, dimensionality of the output space.\n",
    "\n",
    "dropout: Float between 0 and 1. Fraction of the units to drop for the \n",
    "linear transformation of the inputs. Default: 0.\n",
    "\n",
    "recurrent_dropout: Float between 0 and 1. Fraction of the units to drop \n",
    "for the linear transformation of the recurrent state. Default: 0.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1585a8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 30, 50)            1350      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 150)               90900     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 27)                4077      \n",
      "=================================================================\n",
      "Total params: 96,327\n",
      "Trainable params: 96,327\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1.add(Dense(vocab, activation='softmax'))\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1752f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model1.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ce0f1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "199/199 - 15s - loss: 2.7608 - acc: 0.2000 - val_loss: 2.4295 - val_acc: 0.2847\n",
      "Epoch 2/10\n",
      "199/199 - 10s - loss: 2.3039 - acc: 0.3210 - val_loss: 2.2312 - val_acc: 0.3399\n",
      "Epoch 3/10\n",
      "199/199 - 10s - loss: 2.1701 - acc: 0.3521 - val_loss: 2.1318 - val_acc: 0.3697\n",
      "Epoch 4/10\n",
      "199/199 - 10s - loss: 2.0746 - acc: 0.3801 - val_loss: 2.0690 - val_acc: 0.3768\n",
      "Epoch 5/10\n",
      "199/199 - 10s - loss: 1.9749 - acc: 0.4076 - val_loss: 2.0350 - val_acc: 0.4079\n",
      "Epoch 6/10\n",
      "199/199 - 10s - loss: 1.9035 - acc: 0.4314 - val_loss: 1.9607 - val_acc: 0.4348\n",
      "Epoch 7/10\n",
      "199/199 - 10s - loss: 1.8231 - acc: 0.4517 - val_loss: 1.9058 - val_acc: 0.4603\n",
      "Epoch 8/10\n",
      "199/199 - 10s - loss: 1.7467 - acc: 0.4701 - val_loss: 1.8955 - val_acc: 0.4533\n",
      "Epoch 9/10\n",
      "199/199 - 10s - loss: 1.6748 - acc: 0.4930 - val_loss: 1.8758 - val_acc: 0.4703\n",
      "Epoch 10/10\n",
      "199/199 - 10s - loss: 1.6068 - acc: 0.5147 - val_loss: 1.8414 - val_acc: 0.4816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x240e44e4580>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model1.fit(X_tr, y_tr, epochs=10, verbose=2, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0910f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_ returns the value of last executed expression value in Python'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "'''_ returns the value of last executed expression value in Python'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34aa942",
   "metadata": {},
   "source": [
    " # User def function to generate a sequence of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3489ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence of characters with a language model\n",
    "def generate_seq(model1, mapping, seq_length, seed_text, n_chars):\n",
    "\tin_text = seed_text\n",
    "\t# generate a fixed number of characters\n",
    "\tfor _ in range(n_chars): #_ will hold last in_text\n",
    "\t\t# encode the characters as integers\n",
    "\t\tencoded = [mapping[char] for char in in_text]\n",
    "\t\t# truncate sequences to a fixed length\n",
    "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "\t\t# predict character - predict_class function removed so changed the following code[note for Dr Vinod]\n",
    "        # instead of predict_class - np.argmax(model1.predict)\n",
    "\t\tyhat = np.argmax(model1.predict(encoded, verbose=0)) \n",
    "\t\t# reverse map integer to character\n",
    "\t\tout_char = '' #Creating an empty string\n",
    "\t\tfor char, index in mapping.items():\n",
    "\t\t\tif index == yhat:\n",
    "\t\t\t\tout_char = char\n",
    "\t\t\t\tbreak\n",
    "\t\t# append to input\n",
    "\t\tin_text += char\n",
    "\treturn in_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2df520c",
   "metadata": {},
   "source": [
    "# Application of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88afc04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 10).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the fear of the lord is these and the'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Application of model case - 1\n",
    "seed_text = 'the fear of the lord is the'    \n",
    "generate_seq(model1, mapping, 10, seed_text, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4eb436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Application of model case - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "22114fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lovent the repeated for the r'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = 'love'\n",
    "generate_seq(model1,mapping,10,seed_text,25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a570768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Application of model case - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a4e7605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'british the repeated for the rep'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = 'british'\n",
    "generate_seq(model1,mapping,10,seed_text,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5aada6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
